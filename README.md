# ğŸ“œ Scrappy-Doo: ColecciÃ³n de PoesÃ­a en EspaÃ±ol

Proyecto completo para recopilar y visualizar colecciones de poesÃ­a en espaÃ±ol. Incluye un **scraper en Python** para extraer poemas de la web y un **visor en React** para explorar la colecciÃ³n de forma elegante e interactiva.

## ğŸ¯ DescripciÃ³n General

Este proyecto consta de dos componentes principales:

1. **Scraper de Poemas** (`scraper.py`) - Script Python que extrae poemas de [amediavoz.com](https://amediavoz.com), una biblioteca de poesÃ­a hispanoamericana
2. **Visor de Poemas** (`poem-viewer/`) - AplicaciÃ³n React/Vite para explorar y leer la colecciÃ³n

## ğŸ“ Estructura del Proyecto

```
scrappy-doo/
â”œâ”€â”€ scraper.py           # Script de web scraping
â”œâ”€â”€ requirements.txt     # Dependencias de Python
â”œâ”€â”€ poemas.json          # ColecciÃ³n de poemas extraÃ­dos
â”œâ”€â”€ poemas_tmp.json      # Checkpoint temporal del scraping
â”œâ”€â”€ README.md
â””â”€â”€ poem-viewer/         # AplicaciÃ³n frontend React
    â”œâ”€â”€ public/
    â”‚   â””â”€â”€ poemas.json  # Copia de datos para el visor
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.jsx      # Componente principal
    â”‚   â”œâ”€â”€ App.css      # Estilos del componente
    â”‚   â”œâ”€â”€ main.jsx     # Punto de entrada
    â”‚   â””â”€â”€ index.css    # Estilos globales
    â”œâ”€â”€ index.html
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.js
```

---

## ğŸ Scraper de Poemas (Python)

### CaracterÃ­sticas

- **ExtracciÃ³n automÃ¡tica** de poemas desde amediavoz.com
- **NavegaciÃ³n inteligente** por Ã­ndices de autores (A-K, L-Z)
- **DetecciÃ³n de sub-pÃ¡ginas** para autores con mÃºltiples pÃ¡ginas
- **Limpieza de texto** y formato preservado
- **Checkpoints automÃ¡ticos** cada 100 poemas extraÃ­dos
- **EliminaciÃ³n de duplicados** basada en autor + tÃ­tulo
- **Delays configurados** para ser respetuoso con el servidor

### Requisitos

- Python 3.8+
- pip

### InstalaciÃ³n

```bash
pip install -r requirements.txt
```

### Uso

```bash
python scraper.py
```

El scraper:
1. Navega por los Ã­ndices de autores
2. Extrae poemas de cada pÃ¡gina de autor
3. Guarda checkpoints en `poemas_tmp.json`
4. Genera `poemas.json` con todos los poemas Ãºnicos

### Dependencias Python

| Paquete | Uso |
|---------|-----|
| `requests` | Peticiones HTTP |
| `beautifulsoup4` | Parsing de HTML |

---

## âš›ï¸ Visor de Poemas (React)

### CaracterÃ­sticas

- **ExploraciÃ³n visual**: Navega por la colecciÃ³n en una cuadrÃ­cula de tarjetas
- **BÃºsqueda**: Encuentra poemas por tÃ­tulo, autor o contenido
- **Filtrado por autor**: Selecciona un autor especÃ­fico para ver solo sus obras
- **Vista detallada**: Lee cada poema completo con formato preservado
- **DiseÃ±o responsive**: Funciona en desktop, tablet y mÃ³vil
- **Enlaces a fuentes**: Acceso directo a las fuentes originales

### Requisitos

- Node.js 18+ 
- npm o pnpm

### InstalaciÃ³n y Uso

```bash
cd poem-viewer
npm install
npm run dev
```

La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:5173`

### Scripts Disponibles

| Comando | DescripciÃ³n |
|---------|-------------|
| `npm run dev` | Inicia el servidor de desarrollo |
| `npm run build` | Genera la build de producciÃ³n |
| `npm run preview` | Previsualiza la build de producciÃ³n |
| `npm run lint` | Ejecuta el linter |

### ProducciÃ³n

```bash
npm run build
```

Los archivos se generarÃ¡n en la carpeta `dist/`. Puedes servir esta carpeta con cualquier servidor web estÃ¡tico.

---

## ğŸ“„ Formato de Datos

El archivo `poemas.json` contiene un array de objetos con la siguiente estructura:

```json
[
  {
    "autor": "Nombre del Autor",
    "titulo": "TÃ­tulo del Poema",
    "texto": "Contenido del poema...",
    "fuente": "https://url-de-la-fuente.com"
  }
]
```

## ğŸ”„ Flujo de Trabajo

1. Ejecutar `python scraper.py` para extraer poemas
2. Copiar `poemas.json` a `poem-viewer/public/`
3. Ejecutar el visor con `npm run dev`

## ğŸ› ï¸ TecnologÃ­as

| Componente | TecnologÃ­as |
|------------|-------------|
| Scraper | Python, Requests, BeautifulSoup4 |
| Visor | React 19, Vite, CSS |

## âš ï¸ Notas de Uso

- El scraper incluye delays para ser respetuoso con el servidor origen
- Se desactivan las advertencias SSL para sitios con certificados expirados
- Los checkpoints permiten retomar en caso de interrupciÃ³n

## ğŸ“ Licencia

MIT
